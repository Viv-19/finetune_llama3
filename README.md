# finetune_llama3

# LLaMA-3 Fine-Tuning with Unsloth (4-bit)
This project demonstrates how to fine-tune the LLaMA-3 8B model using 4-bit quantization via the Unsloth library. The workflow includes data preparation, model loading, training, and evaluation â€” all designed to be GPU-efficient, especially in Colab environments.




![image](https://github.com/user-attachments/assets/362d653b-c76e-45f2-9080-3ba92528aceb)
