# finetune_llama3

# LLaMA-3 Fine-Tuning with Unsloth (4-bit)
This project demonstrates how to fine-tune the LLaMA-3 8B model using 4-bit quantization via the Unsloth library. The workflow includes data preparation, model loading, training, and evaluation â€” all designed to be GPU-efficient, especially in Colab environments.
